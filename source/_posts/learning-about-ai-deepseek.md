---
title: deepseek学习
abbrlink: 4deb3c87
date: 2025-03-02 16:40:54
updated: 2025-03-12 16:40:54
tags:
  - 大模型
  - AIGC
  - Transformer
categories: AI
---

## 前言
了解并学习一点大模型的原理相关，留档至此
### 更新日志
- 2024-03-12 补充一些名词，名词来源B

<!-- more -->

## 从头开始
*不懂，先罗列一些名词*
- 激活函数
- 神经网络
  - 神经元
  - 输入层
  - 输出层
  - 隐藏层
- 损失函数
  - 均方误差（MSE）
- 线性回归
- 偏导函数
  - 学习率
  - 梯度
- 偏导数
  - 梯度下降
- 链式法则
  - 反向传播
  - 训练（不断的前向传播和反向传播构成）
### 模型问题
- 过拟合（噪声和随机波动导致）
  - 泛化能力（没见过的数据上的能力）
  - 数据增强（创造出更多维度的数据）
    - 模型的鲁棒性
  - 调和的惩罚项
  - 提前终止
  - 正则化（抑制参数的野蛮增长）
    - L1正则化（绝对值）
    - L2正则化（平方）
    - 正则化系数（超参数）
  - Dropout（随机丢弃一部分参数，降低参数的过度依赖）
- 梯度消失
- 梯度爆炸
- 收敛速度
- 计算开销

#### 优化方案
- 梯度裁剪
- 残差网络
- 权重初始化
- 归一化
- 动量法
- RMSProp
- Adam
- mini-batch

## 延伸发展
- 卷积网络CNN
- 循环网络RNN

注意力（attention）机制的引入催发的**Transformer**，尽而衍生出的：**GPT-1，GPT-2，GPT-3，ChatGPT，DeepSeek**

## GRPO算法
